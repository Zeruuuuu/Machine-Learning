{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7748ba81",
   "metadata": {},
   "source": [
    "DSCI 552 Homework 2\n",
    "Zeru Zhou\n",
    "Github username: Zeruuuuu\n",
    "USCID: 9208-8181-38"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b025e6",
   "metadata": {},
   "source": [
    "# Question 1 \n",
    "## (a) Download the AReM data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "c785e899",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from scipy.stats import bootstrap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da9c8b4",
   "metadata": {},
   "source": [
    "Datasets are downloaded."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377e6171",
   "metadata": {},
   "source": [
    "## (b) Keep datasets 1 and 2 in folders bending1 and bending 2, as well as datasets 1, 2, and 3 in other folders as test data and other datasets as train data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "dc4b4b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = []\n",
    "train = []\n",
    "my_dir = '../data/AReM/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "16d813c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bending1', 'bending2', 'cycling', 'lying', 'sitting', 'standing', 'walking']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir_name = sorted([name for name in os.listdir(my_dir) if os.path.isdir(os.path.join(my_dir, name))])\n",
    "dir_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4e464415",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dataset1.csv',\n",
       " 'dataset2.csv',\n",
       " 'dataset3.csv',\n",
       " 'dataset4.csv',\n",
       " 'dataset5.csv',\n",
       " 'dataset6.csv',\n",
       " 'dataset7.csv',\n",
       " 'dataset8.csv',\n",
       " 'dataset9.csv',\n",
       " 'dataset10.csv',\n",
       " 'dataset11.csv',\n",
       " 'dataset12.csv',\n",
       " 'dataset13.csv',\n",
       " 'dataset14.csv',\n",
       " 'dataset15.csv']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(os.listdir('../data/AReM/cycling'), key = lambda x: int(x[7:-4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "915734c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for Dir in dir_name:\n",
    "    files = sorted(os.listdir(os.path.join(my_dir, Dir)),key = lambda x: int(x[7:-4]))\n",
    "    if Dir in ['bending1','bending2']:\n",
    "        for file in files[0:2]:\n",
    "            test.append([pd.read_csv(os.path.join(my_dir, Dir, file), skiprows = 4, usecols = range(7))])\n",
    "        for file in files[2:]:\n",
    "            train.append([pd.read_csv(os.path.join(my_dir, Dir, file), skiprows = 4, usecols = range(7))])\n",
    "    else:\n",
    "        for file in files[0:3]:\n",
    "            test.append([pd.read_csv(os.path.join(my_dir, Dir, file), skiprows = 4, usecols = range(7))])\n",
    "        for file in files[3:]:\n",
    "            train.append([pd.read_csv(os.path.join(my_dir, Dir, file), skiprows = 4, usecols = range(7))])          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "443bf5a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19, 69)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test), len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b4993762",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = []\n",
    "train_df = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9ca86a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for Dir in dir_name:\n",
    "    test_sub = []\n",
    "    train_sub = []\n",
    "    files = sorted(os.listdir(os.path.join(my_dir, Dir)),key = lambda x: int(x[7:-4]))\n",
    "    if Dir in ['bending1','bending2']:\n",
    "        for file in files[0:2]:\n",
    "            test_sub.extend([pd.read_csv(os.path.join(my_dir, Dir, file), skiprows = 4, usecols = range(7))])\n",
    "        for file in files[2:]:\n",
    "            train_sub.extend([pd.read_csv(os.path.join(my_dir, Dir, file), skiprows = 4, usecols = range(7))])\n",
    "    else:\n",
    "        for file in files[0:3]:\n",
    "            test_sub.extend([pd.read_csv(os.path.join(my_dir, Dir, file), skiprows = 4, usecols = range(7))])\n",
    "        for file in files[3:]:\n",
    "            train_sub.extend([pd.read_csv(os.path.join(my_dir, Dir, file), skiprows = 4, usecols = range(7))]) \n",
    "    test_df.append(pd.concat(test_sub))\n",
    "    train_df.append(pd.concat(train_sub))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0dd2a919",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 7)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_df), len(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8cb1ae",
   "metadata": {},
   "source": [
    "As above, I used 2 ways to create train/test:\n",
    "1. put all 19 test dataframes and 69 train dataframes into seperate lists for storage.\n",
    "2. create 1 train dataframe and 1 test dataframe for each action seperately, 7 train and 7 test dataframes as total."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e87d49",
   "metadata": {},
   "source": [
    "## (c) Feature Extraction\n",
    "### Classification of time series usually needs extracting features from them. In this problem, we focus on time-domain features.\n",
    "### (i) Research what types of time-domain features are usually used in time series classification and list them (examples are minimum, maximum, mean, etc)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895793f4",
   "metadata": {},
   "source": [
    "Time domain features used in time series classification are: minimum, maximum, mean, median, standard deviation, first quartile, third quartile, skewness, and kurtosis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef62d6bb",
   "metadata": {},
   "source": [
    "### (ii) Extract the time-domain features minimum, maximum, mean, median, standard deviation, first quartile, and third quartile for all of the 6 time series in each instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "26675489",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict = {'Instance': np.arange(1,89)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "fa271cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for Dir in dir_name:\n",
    "    files = sorted(os.listdir(os.path.join(my_dir, Dir)),key = lambda x: int(x[7:-4]))\n",
    "    for file in files:\n",
    "        df = pd.read_csv(os.path.join(my_dir, Dir, file), skiprows = 4, usecols = range(1,7))\n",
    "        my_dict['label'] = []\n",
    "        num = 0\n",
    "        for columns in df.columns:\n",
    "            num += 1\n",
    "            my_dict[\"min\"+str(num)] = []\n",
    "            my_dict[\"max\"+str(num)] = []\n",
    "            my_dict[\"mean\"+str(num)] = []\n",
    "            my_dict[\"median\"+str(num)] = []\n",
    "            my_dict[\"std\"+str(num)] = []\n",
    "            my_dict[\"1st quart\"+str(num)] = []\n",
    "            my_dict[\"3rd quart\"+str(num)] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "9df8c940",
   "metadata": {},
   "outputs": [],
   "source": [
    "for Dir in dir_name:\n",
    "    files = sorted(os.listdir(os.path.join(my_dir, Dir)),key = lambda x: int(x[7:-4]))\n",
    "    for file in files:\n",
    "        df = pd.read_csv(os.path.join(my_dir, Dir, file), skiprows = 4, usecols = range(1,7))\n",
    "        my_dict['label'].append(Dir)\n",
    "        num = 0\n",
    "        for columns in df.columns:\n",
    "            num += 1\n",
    "            my_dict[\"min\"+str(num)].append(df[columns].min())\n",
    "            my_dict[\"max\"+str(num)].append(df[columns].max())\n",
    "            my_dict[\"mean\"+str(num)].append(df[columns].mean())\n",
    "            my_dict[\"median\"+str(num)].append(df[columns].median())\n",
    "            my_dict[\"std\"+str(num)].append(np.std(df[columns]))\n",
    "            my_dict[\"1st quart\"+str(num)].append(df[columns].describe()[4])\n",
    "            my_dict[\"3rd quart\"+str(num)].append(df[columns].describe()[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "4857dad2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Instance</th>\n",
       "      <th>label</th>\n",
       "      <th>min1</th>\n",
       "      <th>max1</th>\n",
       "      <th>mean1</th>\n",
       "      <th>median1</th>\n",
       "      <th>std1</th>\n",
       "      <th>1st quart1</th>\n",
       "      <th>3rd quart1</th>\n",
       "      <th>min2</th>\n",
       "      <th>...</th>\n",
       "      <th>std5</th>\n",
       "      <th>1st quart5</th>\n",
       "      <th>3rd quart5</th>\n",
       "      <th>min6</th>\n",
       "      <th>max6</th>\n",
       "      <th>mean6</th>\n",
       "      <th>median6</th>\n",
       "      <th>std6</th>\n",
       "      <th>1st quart6</th>\n",
       "      <th>3rd quart6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>bending1</td>\n",
       "      <td>37.25</td>\n",
       "      <td>45.00</td>\n",
       "      <td>40.624792</td>\n",
       "      <td>40.50</td>\n",
       "      <td>1.475428</td>\n",
       "      <td>39.25</td>\n",
       "      <td>42.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.186168</td>\n",
       "      <td>33.0000</td>\n",
       "      <td>36.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.92</td>\n",
       "      <td>0.570583</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.582308</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.3000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>bending1</td>\n",
       "      <td>38.00</td>\n",
       "      <td>45.67</td>\n",
       "      <td>42.812812</td>\n",
       "      <td>42.50</td>\n",
       "      <td>1.434054</td>\n",
       "      <td>42.00</td>\n",
       "      <td>43.6700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.993175</td>\n",
       "      <td>32.0000</td>\n",
       "      <td>34.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.11</td>\n",
       "      <td>0.571083</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.600383</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.3000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>bending1</td>\n",
       "      <td>35.00</td>\n",
       "      <td>47.40</td>\n",
       "      <td>43.954500</td>\n",
       "      <td>44.33</td>\n",
       "      <td>1.557210</td>\n",
       "      <td>43.00</td>\n",
       "      <td>45.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.997520</td>\n",
       "      <td>35.3625</td>\n",
       "      <td>36.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.79</td>\n",
       "      <td>0.493292</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.512971</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>bending1</td>\n",
       "      <td>33.00</td>\n",
       "      <td>47.75</td>\n",
       "      <td>42.179813</td>\n",
       "      <td>43.50</td>\n",
       "      <td>3.666840</td>\n",
       "      <td>39.15</td>\n",
       "      <td>45.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.845436</td>\n",
       "      <td>30.4575</td>\n",
       "      <td>36.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.613521</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.523771</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>bending1</td>\n",
       "      <td>33.00</td>\n",
       "      <td>45.75</td>\n",
       "      <td>41.678063</td>\n",
       "      <td>41.75</td>\n",
       "      <td>2.241152</td>\n",
       "      <td>41.33</td>\n",
       "      <td>42.7500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.408514</td>\n",
       "      <td>28.4575</td>\n",
       "      <td>31.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.79</td>\n",
       "      <td>0.383292</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.388759</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>84</td>\n",
       "      <td>walking</td>\n",
       "      <td>19.50</td>\n",
       "      <td>45.33</td>\n",
       "      <td>33.586875</td>\n",
       "      <td>34.25</td>\n",
       "      <td>4.646088</td>\n",
       "      <td>30.25</td>\n",
       "      <td>37.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.280561</td>\n",
       "      <td>13.7300</td>\n",
       "      <td>18.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.32</td>\n",
       "      <td>3.259729</td>\n",
       "      <td>3.11</td>\n",
       "      <td>1.638534</td>\n",
       "      <td>2.0500</td>\n",
       "      <td>4.3225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>85</td>\n",
       "      <td>walking</td>\n",
       "      <td>19.75</td>\n",
       "      <td>45.50</td>\n",
       "      <td>34.322750</td>\n",
       "      <td>35.25</td>\n",
       "      <td>4.747524</td>\n",
       "      <td>31.00</td>\n",
       "      <td>38.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.116605</td>\n",
       "      <td>13.5000</td>\n",
       "      <td>17.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.67</td>\n",
       "      <td>3.432562</td>\n",
       "      <td>3.20</td>\n",
       "      <td>1.730921</td>\n",
       "      <td>2.1575</td>\n",
       "      <td>4.5650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>86</td>\n",
       "      <td>walking</td>\n",
       "      <td>19.50</td>\n",
       "      <td>46.00</td>\n",
       "      <td>34.546229</td>\n",
       "      <td>35.25</td>\n",
       "      <td>4.837247</td>\n",
       "      <td>31.25</td>\n",
       "      <td>37.8125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.820182</td>\n",
       "      <td>14.0000</td>\n",
       "      <td>17.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>3.338125</td>\n",
       "      <td>3.08</td>\n",
       "      <td>1.655016</td>\n",
       "      <td>2.1600</td>\n",
       "      <td>4.3350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>87</td>\n",
       "      <td>walking</td>\n",
       "      <td>23.50</td>\n",
       "      <td>46.25</td>\n",
       "      <td>34.873229</td>\n",
       "      <td>35.25</td>\n",
       "      <td>4.526997</td>\n",
       "      <td>31.75</td>\n",
       "      <td>38.2500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.127813</td>\n",
       "      <td>13.7500</td>\n",
       "      <td>18.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.51</td>\n",
       "      <td>3.424646</td>\n",
       "      <td>3.27</td>\n",
       "      <td>1.689198</td>\n",
       "      <td>2.1700</td>\n",
       "      <td>4.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>88</td>\n",
       "      <td>walking</td>\n",
       "      <td>19.25</td>\n",
       "      <td>44.00</td>\n",
       "      <td>34.473188</td>\n",
       "      <td>35.00</td>\n",
       "      <td>4.791706</td>\n",
       "      <td>31.25</td>\n",
       "      <td>38.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.153030</td>\n",
       "      <td>13.7300</td>\n",
       "      <td>17.75</td>\n",
       "      <td>0.43</td>\n",
       "      <td>9.00</td>\n",
       "      <td>3.340458</td>\n",
       "      <td>3.09</td>\n",
       "      <td>1.697343</td>\n",
       "      <td>2.1200</td>\n",
       "      <td>4.3750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>88 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Instance     label   min1   max1      mean1  median1      std1  \\\n",
       "0          1  bending1  37.25  45.00  40.624792    40.50  1.475428   \n",
       "1          2  bending1  38.00  45.67  42.812812    42.50  1.434054   \n",
       "2          3  bending1  35.00  47.40  43.954500    44.33  1.557210   \n",
       "3          4  bending1  33.00  47.75  42.179813    43.50  3.666840   \n",
       "4          5  bending1  33.00  45.75  41.678063    41.75  2.241152   \n",
       "..       ...       ...    ...    ...        ...      ...       ...   \n",
       "83        84   walking  19.50  45.33  33.586875    34.25  4.646088   \n",
       "84        85   walking  19.75  45.50  34.322750    35.25  4.747524   \n",
       "85        86   walking  19.50  46.00  34.546229    35.25  4.837247   \n",
       "86        87   walking  23.50  46.25  34.873229    35.25  4.526997   \n",
       "87        88   walking  19.25  44.00  34.473188    35.00  4.791706   \n",
       "\n",
       "    1st quart1  3rd quart1  min2  ...      std5  1st quart5  3rd quart5  min6  \\\n",
       "0        39.25     42.0000   0.0  ...  2.186168     33.0000       36.00  0.00   \n",
       "1        42.00     43.6700   0.0  ...  1.993175     32.0000       34.50  0.00   \n",
       "2        43.00     45.0000   0.0  ...  1.997520     35.3625       36.50  0.00   \n",
       "3        39.15     45.0000   0.0  ...  3.845436     30.4575       36.33  0.00   \n",
       "4        41.33     42.7500   0.0  ...  2.408514     28.4575       31.25  0.00   \n",
       "..         ...         ...   ...  ...       ...         ...         ...   ...   \n",
       "83       30.25     37.0000   0.0  ...  3.280561     13.7300       18.25  0.00   \n",
       "84       31.00     38.0000   0.0  ...  3.116605     13.5000       17.75  0.00   \n",
       "85       31.25     37.8125   0.0  ...  2.820182     14.0000       17.75  0.00   \n",
       "86       31.75     38.2500   0.0  ...  3.127813     13.7500       18.00  0.00   \n",
       "87       31.25     38.0000   0.0  ...  3.153030     13.7300       17.75  0.43   \n",
       "\n",
       "     max6     mean6  median6      std6  1st quart6  3rd quart6  \n",
       "0    1.92  0.570583     0.43  0.582308      0.0000      1.3000  \n",
       "1    3.11  0.571083     0.43  0.600383      0.0000      1.3000  \n",
       "2    1.79  0.493292     0.43  0.512971      0.0000      0.9400  \n",
       "3    2.18  0.613521     0.50  0.523771      0.0000      1.0000  \n",
       "4    1.79  0.383292     0.43  0.388759      0.0000      0.5000  \n",
       "..    ...       ...      ...       ...         ...         ...  \n",
       "83   8.32  3.259729     3.11  1.638534      2.0500      4.3225  \n",
       "84   9.67  3.432562     3.20  1.730921      2.1575      4.5650  \n",
       "85  10.00  3.338125     3.08  1.655016      2.1600      4.3350  \n",
       "86   9.51  3.424646     3.27  1.689198      2.1700      4.5000  \n",
       "87   9.00  3.340458     3.09  1.697343      2.1200      4.3750  \n",
       "\n",
       "[88 rows x 44 columns]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_df = pd.DataFrame(my_dict)\n",
    "my_df = my_df.reset_index(drop = True)\n",
    "my_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3220fd87",
   "metadata": {},
   "source": [
    "As above, dataset with 88 instances is created, with label."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd86c9d",
   "metadata": {},
   "source": [
    "### (iii) Estimate the standard deviation of each of the time-domain features you extracted from the data. Then, use Python’s bootstrapped or any other method to build a 90% bootsrap confidence interval for the standard deviation of each feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "a4fe8a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "std = []\n",
    "for column in my_df.columns[2:]:\n",
    "    std.append(np.std(my_df[column]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "c4d02145",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_col = my_df.columns[2:].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "086e085a",
   "metadata": {},
   "outputs": [],
   "source": [
    "CI = []\n",
    "my_list = my_df.columns[2:].tolist()\n",
    "for column in my_list:\n",
    "    dropped = pd.Series(my_df[column].dropna().tolist())\n",
    "    if dropped.mean() == 0:\n",
    "        CI.append(0)\n",
    "        continue\n",
    "    boot = bootstrap((dropped,), np.std, confidence_level = 0.9)\n",
    "    CI.append(boot.confidence_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "7fab71c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_name</th>\n",
       "      <th>estimated_std</th>\n",
       "      <th>bootstrap CI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>min1</td>\n",
       "      <td>9.568541</td>\n",
       "      <td>(8.522624487992902, 11.222537685083804)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>max1</td>\n",
       "      <td>4.183493</td>\n",
       "      <td>(3.3244398688403445, 5.36505096471005)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mean1</td>\n",
       "      <td>5.246019</td>\n",
       "      <td>(4.751677601400654, 5.9540978610676705)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>median1</td>\n",
       "      <td>5.355577</td>\n",
       "      <td>(4.821639172663221, 6.072196910827445)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>std1</td>\n",
       "      <td>1.759237</td>\n",
       "      <td>(1.5959831109190281, 1.988802513237292)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1st quart1</td>\n",
       "      <td>6.092527</td>\n",
       "      <td>(5.616707948393541, 6.70462962930638)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3rd quart1</td>\n",
       "      <td>5.002031</td>\n",
       "      <td>(4.353549789610109, 5.88500133347144)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>min2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>max2</td>\n",
       "      <td>5.030493</td>\n",
       "      <td>(4.692917794462777, 5.452290237912633)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>mean2</td>\n",
       "      <td>1.568813</td>\n",
       "      <td>(1.4181511681137953, 1.714733578984653)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>median2</td>\n",
       "      <td>1.405398</td>\n",
       "      <td>(1.2497276670776445, 1.549046185597632)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>std2</td>\n",
       "      <td>0.879851</td>\n",
       "      <td>(0.8110696822959046, 0.9427719972013834)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1st quart2</td>\n",
       "      <td>0.942967</td>\n",
       "      <td>(0.8437852126664883, 1.0431065360517064)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3rd quart2</td>\n",
       "      <td>2.119053</td>\n",
       "      <td>(1.9135440108386532, 2.3013635755449204)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>min3</td>\n",
       "      <td>2.937487</td>\n",
       "      <td>(2.780860004841807, 3.1216471179359675)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>max3</td>\n",
       "      <td>4.792067</td>\n",
       "      <td>(4.1849732790497685, 5.519000830011802)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>mean3</td>\n",
       "      <td>3.953833</td>\n",
       "      <td>(3.4429304542259263, 4.532165114427853)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>median3</td>\n",
       "      <td>3.986577</td>\n",
       "      <td>(3.4449447371540374, 4.57842764619191)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>std3</td>\n",
       "      <td>0.945537</td>\n",
       "      <td>(0.8080708375749417, 1.209518744632088)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1st quart3</td>\n",
       "      <td>4.160032</td>\n",
       "      <td>(3.649121904080775, 4.722023121719325)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3rd quart3</td>\n",
       "      <td>4.129511</td>\n",
       "      <td>(3.599929022113363, 4.7685455903468865)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>min4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>max4</td>\n",
       "      <td>2.169234</td>\n",
       "      <td>(2.003110820885625, 2.39707017281568)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>mean4</td>\n",
       "      <td>1.161534</td>\n",
       "      <td>(1.080391151324363, 1.2198873306843323)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>median4</td>\n",
       "      <td>1.141971</td>\n",
       "      <td>(1.0573346946907063, 1.1987516025948766)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>std4</td>\n",
       "      <td>0.455494</td>\n",
       "      <td>(0.42435063205451135, 0.48755335330518823)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1st quart4</td>\n",
       "      <td>0.840050</td>\n",
       "      <td>(0.7788102104721966, 0.890949255154336)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>3rd quart4</td>\n",
       "      <td>1.546271</td>\n",
       "      <td>(1.438096343166927, 1.6238019126320546)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>min5</td>\n",
       "      <td>6.085924</td>\n",
       "      <td>(4.705949160340787, 7.852170655689672)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>max5</td>\n",
       "      <td>5.740079</td>\n",
       "      <td>(4.907725444384956, 6.708467753473753)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>mean5</td>\n",
       "      <td>5.671149</td>\n",
       "      <td>(4.671151699669637, 7.002879900225299)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>median5</td>\n",
       "      <td>5.810683</td>\n",
       "      <td>(4.768327588694959, 7.213740723066064)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>std5</td>\n",
       "      <td>1.005474</td>\n",
       "      <td>(0.8451808907785892, 1.2777244597920994)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1st quart5</td>\n",
       "      <td>6.086856</td>\n",
       "      <td>(5.008942093131382, 7.434618089739396)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>3rd quart5</td>\n",
       "      <td>5.531486</td>\n",
       "      <td>(4.570272312936763, 6.7142544012024095)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>min6</td>\n",
       "      <td>0.045835</td>\n",
       "      <td>(0.0, 0.06444269044223307)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>max6</td>\n",
       "      <td>2.518912</td>\n",
       "      <td>(2.3093819085874263, 2.8496219093750987)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>mean6</td>\n",
       "      <td>1.150552</td>\n",
       "      <td>(1.0685097591799537, 1.214125982028177)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>median6</td>\n",
       "      <td>1.083576</td>\n",
       "      <td>(1.0040434354057968, 1.1500536520292044)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>std6</td>\n",
       "      <td>0.513453</td>\n",
       "      <td>(0.4828137927257127, 0.5447839717623837)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1st quart6</td>\n",
       "      <td>0.757152</td>\n",
       "      <td>(0.6977439830672121, 0.8106175306525891)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>3rd quart6</td>\n",
       "      <td>1.518071</td>\n",
       "      <td>(1.4069865086912685, 1.5979290572253744)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_name  estimated_std                                bootstrap CI\n",
       "0          min1       9.568541     (8.522624487992902, 11.222537685083804)\n",
       "1          max1       4.183493      (3.3244398688403445, 5.36505096471005)\n",
       "2         mean1       5.246019     (4.751677601400654, 5.9540978610676705)\n",
       "3       median1       5.355577      (4.821639172663221, 6.072196910827445)\n",
       "4          std1       1.759237     (1.5959831109190281, 1.988802513237292)\n",
       "5    1st quart1       6.092527       (5.616707948393541, 6.70462962930638)\n",
       "6    3rd quart1       5.002031       (4.353549789610109, 5.88500133347144)\n",
       "7          min2       0.000000                                           0\n",
       "8          max2       5.030493      (4.692917794462777, 5.452290237912633)\n",
       "9         mean2       1.568813     (1.4181511681137953, 1.714733578984653)\n",
       "10      median2       1.405398     (1.2497276670776445, 1.549046185597632)\n",
       "11         std2       0.879851    (0.8110696822959046, 0.9427719972013834)\n",
       "12   1st quart2       0.942967    (0.8437852126664883, 1.0431065360517064)\n",
       "13   3rd quart2       2.119053    (1.9135440108386532, 2.3013635755449204)\n",
       "14         min3       2.937487     (2.780860004841807, 3.1216471179359675)\n",
       "15         max3       4.792067     (4.1849732790497685, 5.519000830011802)\n",
       "16        mean3       3.953833     (3.4429304542259263, 4.532165114427853)\n",
       "17      median3       3.986577      (3.4449447371540374, 4.57842764619191)\n",
       "18         std3       0.945537     (0.8080708375749417, 1.209518744632088)\n",
       "19   1st quart3       4.160032      (3.649121904080775, 4.722023121719325)\n",
       "20   3rd quart3       4.129511     (3.599929022113363, 4.7685455903468865)\n",
       "21         min4       0.000000                                           0\n",
       "22         max4       2.169234       (2.003110820885625, 2.39707017281568)\n",
       "23        mean4       1.161534     (1.080391151324363, 1.2198873306843323)\n",
       "24      median4       1.141971    (1.0573346946907063, 1.1987516025948766)\n",
       "25         std4       0.455494  (0.42435063205451135, 0.48755335330518823)\n",
       "26   1st quart4       0.840050     (0.7788102104721966, 0.890949255154336)\n",
       "27   3rd quart4       1.546271     (1.438096343166927, 1.6238019126320546)\n",
       "28         min5       6.085924      (4.705949160340787, 7.852170655689672)\n",
       "29         max5       5.740079      (4.907725444384956, 6.708467753473753)\n",
       "30        mean5       5.671149      (4.671151699669637, 7.002879900225299)\n",
       "31      median5       5.810683      (4.768327588694959, 7.213740723066064)\n",
       "32         std5       1.005474    (0.8451808907785892, 1.2777244597920994)\n",
       "33   1st quart5       6.086856      (5.008942093131382, 7.434618089739396)\n",
       "34   3rd quart5       5.531486     (4.570272312936763, 6.7142544012024095)\n",
       "35         min6       0.045835                  (0.0, 0.06444269044223307)\n",
       "36         max6       2.518912    (2.3093819085874263, 2.8496219093750987)\n",
       "37        mean6       1.150552     (1.0685097591799537, 1.214125982028177)\n",
       "38      median6       1.083576    (1.0040434354057968, 1.1500536520292044)\n",
       "39         std6       0.513453    (0.4828137927257127, 0.5447839717623837)\n",
       "40   1st quart6       0.757152    (0.6977439830672121, 0.8106175306525891)\n",
       "41   3rd quart6       1.518071    (1.4069865086912685, 1.5979290572253744)"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe = pd.DataFrame({'feature_name': my_col, 'estimated_std': std, 'bootstrap CI': CI})\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e17e06f",
   "metadata": {},
   "source": [
    "As above, I created a table consist of feature names, estimated std, and bootstrap CI for each features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab84d01",
   "metadata": {},
   "source": [
    "### (iv) Use your judgement to select the three most important time-domain features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac0562a",
   "metadata": {},
   "source": [
    "A good time domain feature should be closely related to time and scale the whole set of data instead of only part of them. In this case, features like 1st quart & median & 3rd quart may not be as good as min, max, and mean. Hence, my choice of three most important time-domain features are min, max, and mean, since they take looks at the whole dataset instead of only part of them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d225fb",
   "metadata": {},
   "source": [
    "# Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3bfacb7",
   "metadata": {},
   "source": [
    "### I collect a set of data (n = 100 observations) containing a single predictor and a quantitative response. I then fit a linear regression model to the data, as well as a separate cubic regression, i.e. Y = β0 + β1X + β2X2 + β3X3 + ϵ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918f7674",
   "metadata": {},
   "source": [
    "### (a) Suppose that the true relationship between X and Y is linear, i.e. Y = β0 + β1X + ϵ. Consider the training residual sum of squares (RSS) for the linear regression, and also the training RSS for the cubic regression. Would we expect one to be lower than the other, would we expect them to be the same, or is there not enough information to tell? Justify your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33838bc2",
   "metadata": {},
   "source": [
    "I would expect the cubic regression would have a lower RSS than the linear regression. This is because in training process, higher degree of polynomial features would fit more tightly against the data, hence make the train error very small. So, the cubic regression would have a lower RSS than the linear regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997b14e8",
   "metadata": {},
   "source": [
    "### (b) Answer (a) using test rather than training RSS."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c73e2d",
   "metadata": {},
   "source": [
    "In this case, I would expect the linear regression would have a lower RSS than the cubic regression. Since the true relationship is linear, the cubic regression would overfit the training set and it would be only very good at predicting the training set. For the test set, cubic regression would perform worse because of the overfitting problem. Hence, the linear regression would have a lower RSS than the cubic regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe3eb06",
   "metadata": {},
   "source": [
    "### (c) Suppose that the true relationship between X and Y is not linear, but we don’t know how far it is from linear. Consider the training RSS for the linear regression, and also the training RSS for the cubic regression. Would we expect one to be lower than the other, would we expect them to be the same, or is there not enough information to tell? Justify your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f158377",
   "metadata": {},
   "source": [
    "I would expect the cubic regression have a lower RSS than the linear regression. This is because higher degree of polynomial feature would be more flexible, and would follow the data more closely and tightly no matter what true distribution is. Thus, cubic regression would perform better and has lower RSS than linear regression in the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644d1d6b",
   "metadata": {},
   "source": [
    "### (d) Answer (c) using test rather than training RSS."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2893d4be",
   "metadata": {},
   "source": [
    "There is not enough information to tell which model could have lower RSS since we don't know the true distribution is how far from linear. If it is closer to linear, then linear regression would have a lower RSS; if it is closer to cubic, then cubic regression would have a lower RSS. We can know which better only if we know what true distribution is and thereby adjust the flexibility of the model to provide the optimized RSS. Hence, there is not enough information to tell which model could have lower RSS."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
